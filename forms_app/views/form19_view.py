import pandas as pd
import numpy as np
from io import BytesIO
from datetime import datetime
import time
import uuid
import warnings
from django import forms
from django.shortcuts import render, redirect
from django.contrib.auth.decorators import login_required
from django.contrib import messages
from django.http import HttpResponse
from openpyxl import Workbook
from openpyxl.styles import Font, Alignment, PatternFill, Border, Side
from openpyxl.utils import get_column_letter
from django.views.decorators.csrf import csrf_protect
from urllib.parse import quote

warnings.filterwarnings("ignore")


# ===== –§–û–†–ú–ê =====
class Form19AdvancedUploadForm(forms.Form):
    """–ü—Ä–æ—Å—Ç–∞—è —Ñ–æ—Ä–º–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–∞ –¥–ª—è —Ñ–æ—Ä–º—ã 19 - –∞–Ω–∞–ª–∏–∑ —Ç—Ä–∞—Ñ–∏–∫–∞ –ø–æ —Ä–µ–≥–∏–æ–Ω–∞–º –∏ –≥–æ—Ä–æ–¥–∞–º"""

    file = forms.FileField(
        label="–§–∞–π–ª —Å –¥–∞–Ω–Ω—ã–º–∏ –ø–æ –∑–∞–∫–∞–∑–∞–º",
        widget=forms.FileInput(
            attrs={
                "class": "form-control",
                "accept": ".xlsx,.xls,.csv",
            }
        ),
    )

    def clean_file(self):
        file = self.cleaned_data["file"]
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ
        if not file.name.endswith((".xlsx", ".xls", ".csv")):
            raise forms.ValidationError(
                "–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è —Ç–æ–ª—å–∫–æ —Ñ–∞–π–ª—ã Excel (.xlsx, .xls) –∏ CSV (.csv)"
            )
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä (–º–∞–∫—Å–∏–º—É–º 50 –ú–ë)
        max_size = 50 * 1024 * 1024  # 50 –ú–ë
        if file.size > max_size:
            raise forms.ValidationError(
                f"–†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ –Ω–µ –¥–æ–ª–∂–µ–Ω –ø—Ä–µ–≤—ã—à–∞—Ç—å 50 –ú–ë. –í–∞—à —Ñ–∞–π–ª: {file.size / (1024*1024):.1f} –ú–ë"
            )
        return file


# ===== VIEW =====
@login_required
@csrf_protect
def form19_view(request):
    """–§–æ—Ä–º–∞ 19 - –∞–Ω–∞–ª–∏–∑ —Ç—Ä–∞—Ñ–∏–∫–∞ –ø–æ —Ä–µ–≥–∏–æ–Ω–∞–º –∏ –≥–æ—Ä–æ–¥–∞–º"""
    if request.method == "GET":
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –Ω–æ–≤—ã–π —Ç–æ–∫–µ–Ω –¥–ª—è —ç—Ç–æ–π —Å–µ—Å—Å–∏–∏
        request.session["form19_upload_token"] = str(uuid.uuid4())
        request.session.pop("form19_last_upload", None)
        form = Form19AdvancedUploadForm()
        context = {
            "page_title": "–§–æ—Ä–º–∞ 19: –ê–Ω–∞–ª–∏–∑ —Ç—Ä–∞—Ñ–∏–∫–∞ –ø–æ —Ä–µ–≥–∏–æ–Ω–∞–º –∏ –≥–æ—Ä–æ–¥–∞–º",
            "upload_token": request.session["form19_upload_token"],
            "form": form,
        }
        return render(request, "forms_app/form19.html", context)

    elif request.method == "POST":
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–æ–∫–µ–Ω
        post_token = request.POST.get("upload_token")
        session_token = request.session.get("form19_upload_token")
        if not post_token or post_token != session_token:
            messages.warning(
                request, "–ù–µ–≤–µ—Ä–Ω—ã–π —Ç–æ–∫–µ–Ω —Å–µ—Å—Å–∏–∏. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ–±–Ω–æ–≤–∏—Ç–µ —Å—Ç—Ä–∞–Ω–∏—Ü—É."
            )
            return redirect("forms_app:form19_view")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ñ–∞–π–ª–∞
        if "file" not in request.FILES:
            messages.error(request, "‚ùå –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤—ã–±–µ—Ä–∏—Ç–µ —Ñ–∞–π–ª –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏!")
            return redirect("forms_app:form19_view")

        try:
            start_time = time.time()
            uploaded_file = request.FILES["file"]

            # –ß–∏—Ç–∞–µ–º —Ñ–∞–π–ª
            if uploaded_file.name.endswith(".csv"):
                df = pd.read_csv(uploaded_file, encoding="utf-8")
            else:
                try:
                    df = pd.read_excel(uploaded_file, sheet_name="–ó–∞–∫–∞–∑—ã", header=1)
                except:
                    df = pd.read_excel(uploaded_file)

            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ–ª–æ–Ω–∫–∏
            region_from_col, region_to_col = find_region_columns(df)
            city_from_col, city_to_col = find_city_columns(df)

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–∞–π–¥–µ–Ω—ã –ª–∏ –∫–∞–∫–∏–µ-–ª–∏–±–æ –∫–æ–ª–æ–Ω–∫–∏
            if not (region_from_col and region_to_col) and not (
                city_from_col and city_to_col
            ):
                messages.error(
                    request,
                    "‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∫–æ–ª–æ–Ω–∫–∏ '–†–µ–≥–∏–æ–Ω –æ—Ç–ø—Ä–∞–≤–∫–∏/–ø—Ä–∏–±—ã—Ç–∏—è' –∏–ª–∏ '–ì–æ—Ä–æ–¥ –æ—Ç–ø—Ä–∞–≤–∫–∏/–ø—Ä–∏–±—ã—Ç–∏—è'. "
                    "–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –≤ —Ñ–∞–π–ª–µ –µ—Å—Ç—å –∫–æ–ª–æ–Ω–∫–∏ —Å –Ω–∞–∑–≤–∞–Ω–∏—è–º–∏ '–†–µ–≥–∏–æ–Ω –æ—Ç–ø—Ä–∞–≤–∫–∏', '–†–µ–≥–∏–æ–Ω –ø—Ä–∏–±—ã—Ç–∏—è' "
                    "–∏–ª–∏ –Ω–µ–Ω–∞–∑–≤–∞–Ω–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ (Unnamed), —Å–æ–¥–µ—Ä–∂–∞—â–∏–µ —Å–ª–æ–≤–∞ '–≠–ª–µ–∫—Ç—Ä–æ—Å—Ç–∞–ª—å', '–ö–æ–ª–µ–¥–∏–Ω–æ', '–ú–æ—Å–∫–≤–∞', '–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥'.",
                )
                return redirect("forms_app:form19_view")

            all_analyses = {}
            all_destination_analyses = {}

            # –ê–Ω–∞–ª–∏–∑ –ø–æ —Ä–µ–≥–∏–æ–Ω–∞–º
            if region_from_col and region_to_col:
                print(
                    f"üîç –ù–∞–π–¥–µ–Ω—ã –∫–æ–ª–æ–Ω–∫–∏ —Ä–µ–≥–∏–æ–Ω–æ–≤: '{region_from_col}' -> '{region_to_col}'"
                )
                region_analysis_result = analyze_traffic(
                    df, region_from_col, region_to_col, "–†–µ–≥–∏–æ–Ω—ã"
                )
                if region_analysis_result is not None:
                    all_analyses["regions"] = region_analysis_result
                    region_destination_result = analyze_destinations_by_sources(
                        df, region_from_col, region_to_col, "–†–µ–≥–∏–æ–Ω—ã"
                    )
                    if region_destination_result is not None:
                        all_destination_analyses["regions"] = region_destination_result
                else:
                    print("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–≤–µ—Å—Ç–∏ –∞–Ω–∞–ª–∏–∑ –ø–æ —Ä–µ–≥–∏–æ–Ω–∞–º.")

            # –ê–Ω–∞–ª–∏–∑ –ø–æ –≥–æ—Ä–æ–¥–∞–º
            if city_from_col and city_to_col:
                print(
                    f"üîç –ù–∞–π–¥–µ–Ω—ã –∫–æ–ª–æ–Ω–∫–∏ –≥–æ—Ä–æ–¥–æ–≤: '{city_from_col}' -> '{city_to_col}'"
                )
                city_analysis_result = analyze_traffic(
                    df, city_from_col, city_to_col, "–ì–æ—Ä–æ–¥–∞"
                )
                if city_analysis_result is not None:
                    all_analyses["cities"] = city_analysis_result
                    city_destination_result = analyze_destinations_by_sources(
                        df, city_from_col, city_to_col, "–ì–æ—Ä–æ–¥–∞"
                    )
                    if city_destination_result is not None:
                        all_destination_analyses["cities"] = city_destination_result
                else:
                    print("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–≤–µ—Å—Ç–∏ –∞–Ω–∞–ª–∏–∑ –ø–æ –≥–æ—Ä–æ–¥–∞–º.")

            # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–≤–µ—Å—Ç–∏ –Ω–∏ –æ–¥–∏–Ω –∞–Ω–∞–ª–∏–∑
            if not all_analyses:
                messages.error(
                    request,
                    "‚ùå –ù–∏ –æ–¥–∏–Ω –∏–∑ –∞–Ω–∞–ª–∏–∑–æ–≤ (–ø–æ —Ä–µ–≥–∏–æ–Ω–∞–º –∏–ª–∏ –≥–æ—Ä–æ–¥–∞–º) –Ω–µ –¥–∞–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤.",
                )
                return redirect("forms_app:form19_view")

            # –°–æ–∑–¥–∞–µ–º Excel –æ—Ç—á–µ—Ç
            excel_buffer = create_excel_report_with_proper_names(
                df, all_analyses, all_destination_analyses
            )
            processing_time = time.time() - start_time

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            request.session["form19_processing_time"] = processing_time
            request.session["form19_analysis_count"] = len(all_analyses)
            request.session.modified = True

            # –û—á–∏—â–∞–µ–º —Å–µ—Å—Å–∏—é –ø–æ—Å–ª–µ –æ—Ç–ø—Ä–∞–≤–∫–∏ —Ñ–∞–π–ª–∞
            request.session.pop("form19_last_upload", None)

            # –°–æ–∑–¥–∞–µ–º –∏–º—è —Ñ–∞–π–ª–∞ –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
            original_name = uploaded_file.name.rsplit(".", 1)[0]
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"–∞–Ω–∞–ª–∏–∑_—Ç—Ä–∞—Ñ–∏–∫–∞_—Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã_{original_name}_{timestamp}.xlsx"

            # –°–æ–∑–¥–∞–µ–º HttpResponse —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏ –∑–∞–≥–æ–ª–æ–≤–∫–∞–º–∏
            response = HttpResponse(
                excel_buffer.getvalue(),
                content_type="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            )
            safe_filename = quote(filename.encode("utf-8"))
            response["Content-Disposition"] = (
                f"attachment; filename*=UTF-8''{safe_filename}"
            )
            response["Cache-Control"] = "no-store, no-cache, must-revalidate, max-age=0"
            response["Pragma"] = "no-cache"
            response["Expires"] = "Mon, 01 Jan 1990 00:00:00 GMT"

            return response

        except Exception as e:
            messages.error(request, f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞: {str(e)}")
            import traceback

            print(traceback.format_exc())
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –Ω–∞ –≥–ª–∞–≤–Ω—É—é —Å –Ω–æ–≤—ã–º —Ç–æ–∫–µ–Ω–æ–º
            request.session["form19_upload_token"] = str(uuid.uuid4())
            return redirect("forms_app:form19_view")


# ===== –§–£–ù–ö–¶–ò–ò –ê–ù–ê–õ–ò–ó–ê =====
def find_region_columns(df):
    """–ù–∞—Ö–æ–¥–∏—Ç –∫–æ–ª–æ–Ω–∫–∏ '–†–µ–≥–∏–æ–Ω –æ—Ç–ø—Ä–∞–≤–∫–∏' –∏ '–†–µ–≥–∏–æ–Ω –ø—Ä–∏–±—ã—Ç–∏—è' –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é."""
    region_from_col = None
    region_to_col = None

    for col_name in df.columns:
        # –ü—Ä–∏–≤–æ–¥–∏–º –∫ —Å—Ç—Ä–æ–∫–µ –∏ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É –¥–ª—è –ø–æ–∏—Å–∫–∞
        name_lower = str(col_name).lower()
        if "—Ä–µ–≥–∏–æ–Ω" in name_lower and "–æ—Ç–ø—Ä–∞–≤" in name_lower:
            region_from_col = col_name
        elif "—Ä–µ–≥–∏–æ–Ω" in name_lower and (
            "–ø—Ä–∏–±—ã—Ç" in name_lower or "–Ω–∞–∑–Ω–∞—á" in name_lower
        ):
            region_to_col = col_name

    return region_from_col, region_to_col


def find_city_columns(df):
    """–ù–∞—Ö–æ–¥–∏—Ç –∫–æ–ª–æ–Ω–∫–∏ '–ì–æ—Ä–æ–¥ –æ—Ç–ø—Ä–∞–≤–∫–∏' –∏ '–ì–æ—Ä–æ–¥ –ø—Ä–∏–±—ã—Ç–∏—è' –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º –≤ –Ω–µ–Ω–∞–∑–≤–∞–Ω–Ω—ã—Ö –∫–æ–ª–æ–Ω–∫–∞—Ö."""
    city_from_col = None
    city_to_col = None

    # –ò–∑–≤–µ—Å—Ç–Ω—ã–µ –≥–æ—Ä–æ–¥–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –∏ –ø—Ä–∏–±—ã—Ç–∏—è (–≤ –Ω–∏–∂–Ω–µ–º —Ä–µ–≥–∏—Å—Ç—Ä–µ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è)
    known_cities_from_lower = {"—ç–ª–µ–∫—Ç—Ä–æ—Å—Ç–∞–ª—å", "–∫–æ–ª–µ–¥–∏–Ω–æ"}
    known_cities_to_lower = {
        "–º–æ—Å–∫–≤–∞",
        "—Å–∞–Ω–∫—Ç-–ø–µ—Ç–µ—Ä–±—É—Ä–≥",
        "–æ–º—Å–∫",
        "—á–µ–ª—è–±–∏–Ω—Å–∫",
        "—Å–∞–º–∞—Ä–∞",
        "–¥–µ—Ä–µ–≤–Ω—è",
        "–ø–æ—Å—ë–ª–æ–∫",
        "—Å–µ–ª–æ",
        "—Ç—É–ª–∞",
    }

    print("\nüîç –ù–ê–ß–ò–ù–ê–ï–ú –ü–û–ò–°–ö –ö–û–õ–û–ù–û–ö –° –ì–û–†–û–î–ê–ú–ò:")
    print(f"–í—Å–µ–≥–æ –∫–æ–ª–æ–Ω–æ–∫ –≤ —Ñ–∞–π–ª–µ: {len(df.columns)}")

    for idx, col_name in enumerate(df.columns):
        col_name_str = str(col_name).strip()
        print(f"\n  –ö–æ–ª–æ–Ω–∫–∞ {idx}: '{col_name_str}'")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –∫–æ–ª–æ–Ω–∫–∞ –Ω–µ–Ω–∞–∑–≤–∞–Ω–Ω–æ–π
        is_unnamed = col_name_str.startswith("Unnamed:") or col_name_str == ""
        print(f"    –¢–∏–ø: {'–ù–µ–Ω–∞–∑–≤–∞–Ω–Ω–∞—è' if is_unnamed else '–° –Ω–∞–∑–≤–∞–Ω–∏–µ–º'}")

        if not is_unnamed:
            continue  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∫–æ–ª–æ–Ω–∫–∏ —Å –Ω–∞–∑–≤–∞–Ω–∏—è–º–∏

        # –ü–æ–ª—É—á–∞–µ–º –æ–±—Ä–∞–∑–µ—Ü –¥–∞–Ω–Ω—ã—Ö –∏–∑ —ç—Ç–æ–π –∫–æ–ª–æ–Ω–∫–∏
        non_null_data = df[col_name].dropna()
        print(f"    –ù–µ–ø—É—Å—Ç—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π: {len(non_null_data)} –∏–∑ {len(df)}")

        if len(non_null_data) == 0:
            print("    –ü—Ä–æ–ø—É—Å–∫–∞–µ–º - –∫–æ–ª–æ–Ω–∫–∞ –ø—É—Å—Ç–∞—è")
            continue

        # –ü–æ–ª—É—á–∞–µ–º –æ–±—Ä–∞–∑–µ—Ü –¥–∞–Ω–Ω—ã—Ö –∏ –ø—Ä–∏–≤–æ–¥–∏–º –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É
        sample_data = non_null_data.head(20).astype(str).str.strip()
        sample_data_lower = sample_data.str.lower().tolist()

        print(
            f"    –û–±—Ä–∞–∑–µ—Ü –¥–∞–Ω–Ω—ã—Ö (–ø–µ—Ä–≤—ã–µ {len(sample_data_lower)}): {sample_data_lower[:5]}"
        )

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∏ –∫–æ–ª–æ–Ω–∫–∞ –∏–∑–≤–µ—Å—Ç–Ω—ã–µ –≥–æ—Ä–æ–¥–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏
        found_from_cities = []
        for city_word in known_cities_from_lower:
            for data_item in sample_data_lower:
                if city_word in data_item:
                    found_from_cities.append(city_word)
                    break

        if found_from_cities:
            print(f"    –ù–∞–π–¥–µ–Ω—ã –≥–æ—Ä–æ–¥–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏: {found_from_cities}")
            if city_from_col is None:
                city_from_col = col_name
                print(f"    ‚úÖ –£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –∫–∞–∫ '–ì–æ—Ä–æ–¥ –æ—Ç–ø—Ä–∞–≤–∫–∏': '{col_name}'")
        else:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∏ –∫–æ–ª–æ–Ω–∫–∞ –∏–∑–≤–µ—Å—Ç–Ω—ã–µ –≥–æ—Ä–æ–¥–∞ –ø—Ä–∏–±—ã—Ç–∏—è
            found_to_cities = []
            for city_word in known_cities_to_lower:
                for data_item in sample_data_lower:
                    if city_word in data_item:
                        found_to_cities.append(city_word)
                        break

            if found_to_cities:
                print(f"    –ù–∞–π–¥–µ–Ω—ã –≥–æ—Ä–æ–¥–∞ –ø—Ä–∏–±—ã—Ç–∏—è: {found_to_cities}")
                if city_to_col is None:
                    city_to_col = col_name
                    print(f"    ‚úÖ –£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –∫–∞–∫ '–ì–æ—Ä–æ–¥ –ø—Ä–∏–±—ã—Ç–∏—è': '{col_name}'")
            else:
                print("    –ù–µ –Ω–∞–π–¥–µ–Ω—ã –∏–∑–≤–µ—Å—Ç–Ω—ã–µ –≥–æ—Ä–æ–¥–∞")

    print(f"\nüìä –†–ï–ó–£–õ–¨–¢–ê–¢–´ –ü–û–ò–°–ö–ê:")
    print(f"  –ì–æ—Ä–æ–¥ –æ—Ç–ø—Ä–∞–≤–∫–∏: {city_from_col}")
    print(f"  –ì–æ—Ä–æ–¥ –ø—Ä–∏–±—ã—Ç–∏—è: {city_to_col}")

    return city_from_col, city_to_col


def analyze_traffic(df, from_col, to_col, analysis_name):
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞ —Ç—Ä–∞—Ñ–∏–∫–∞"""
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –∫–æ–ª–æ–Ω–∫–∏ —Å—É—â–µ—Å—Ç–≤—É—é—Ç
    if from_col not in df.columns or to_col not in df.columns:
        return None

    # –û—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    df_clean = df.copy()
    df_clean[from_col] = df_clean[from_col].astype(str).str.strip()
    df_clean[to_col] = df_clean[to_col].astype(str).str.strip()

    # –£–¥–∞–ª—è–µ–º –ø—É—Å—Ç—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
    df_clean = df_clean[df_clean[from_col] != "nan"]
    df_clean = df_clean[df_clean[to_col] != "nan"]
    df_clean = df_clean[df_clean[from_col] != ""]
    df_clean = df_clean[df_clean[to_col] != ""]

    total_records = len(df_clean)
    if total_records == 0:
        return None

    # 1. –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ —Ç—Ä–∞—Ñ–∏–∫–∞
    traffic_volume = (
        df_clean.groupby([from_col, to_col]).size().reset_index(name="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ")
    )
    traffic_volume = traffic_volume.sort_values("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ", ascending=False)

    # 2. –ú–∞—Ç—Ä–∏—Ü–∞ —Ç—Ä–∞—Ñ–∏–∫–∞
    traffic_matrix = traffic_volume.pivot_table(
        index=from_col, columns=to_col, values="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ", fill_value=0
    ).astype(int)

    # 3. –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    unique_sources = df_clean[from_col].nunique()
    unique_destinations = df_clean[to_col].nunique()
    unique_routes = len(traffic_volume)

    # 4. –í–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ/–≤–Ω–µ—à–Ω–∏–µ –ø–µ—Ä–µ–≤–æ–∑–∫–∏
    internal = df_clean[df_clean[from_col] == df_clean[to_col]].shape[0]
    external = total_records - internal
    internal_pct = (internal / total_records * 100) if total_records > 0 else 0
    external_pct = (external / total_records * 100) if total_records > 0 else 0

    # 5. –¢–æ–ø –º–∞—Ä—à—Ä—É—Ç–æ–≤
    top_n = min(10, len(traffic_volume))
    top_routes = traffic_volume.head(top_n)

    return {
        "df": df_clean,
        "from_col": from_col,
        "to_col": to_col,
        "analysis_name": analysis_name,
        "traffic_volume": traffic_volume,
        "traffic_matrix": traffic_matrix,
        "total_records": total_records,
        "unique_sources": unique_sources,
        "unique_destinations": unique_destinations,
        "unique_routes": unique_routes,
        "internal": internal,
        "external": external,
        "internal_pct": internal_pct,
        "external_pct": external_pct,
        "top_routes": top_routes,
    }


def analyze_destinations_by_sources(df, from_col, to_col, analysis_name):
    """–ê–Ω–∞–ª–∏–∑ –≥–æ—Ä–æ–¥–æ–≤ –ø—Ä–∏–±—ã—Ç–∏—è —Å –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–æ–π –ø–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º"""
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –∫–æ–ª–æ–Ω–∫–∏ —Å—É—â–µ—Å—Ç–≤—É—é—Ç
    if from_col not in df.columns or to_col not in df.columns:
        return None

    # –û—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    df_clean = df.copy()
    df_clean[from_col] = df_clean[from_col].astype(str).str.strip()
    df_clean[to_col] = df_clean[to_col].astype(str).str.strip()

    # –£–¥–∞–ª—è–µ–º –ø—É—Å—Ç—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
    df_clean = df_clean[df_clean[from_col] != "nan"]
    df_clean = df_clean[df_clean[to_col] != "nan"]
    df_clean = df_clean[df_clean[from_col] != ""]
    df_clean = df_clean[df_clean[to_col] != ""]

    total_records = len(df_clean)
    if total_records == 0:
        return None

    # 1. –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ –≥–æ—Ä–æ–¥–∞–º –ø—Ä–∏–±—ã—Ç–∏—è
    destinations_total = (
        df_clean.groupby(to_col).size().reset_index(name="–í—Å–µ–≥–æ_–ø–æ—Å—Ç—É–ø–ª–µ–Ω–∏–π")
    )
    destinations_total = destinations_total.sort_values(
        "–í—Å–µ–≥–æ_–ø–æ—Å—Ç—É–ø–ª–µ–Ω–∏–π", ascending=False
    )

    # 2. –î–µ—Ç–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –≥–æ—Ä–æ–¥–∞ –ø—Ä–∏–±—ã—Ç–∏—è
    pivot_table = (
        df_clean.groupby([to_col, from_col]).size().reset_index(name="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ")
    )
    pivot_table = pivot_table.sort_values(
        [to_col, "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ"], ascending=[True, False]
    )

    # 3. –°–æ–∑–¥–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è Excel
    destinations_detail = {}
    for dest_city in destinations_total[to_col].head(50):  # –û–≥—Ä–∞–Ω–∏—á–∏–º —Ç–æ–ø-50 –≥–æ—Ä–æ–¥–æ–≤
        # –§–∏–ª—å—Ç—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –≥–æ—Ä–æ–¥–∞ –ø—Ä–∏–±—ã—Ç–∏—è
        dest_data = pivot_table[pivot_table[to_col] == dest_city]

        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É
        dest_data = dest_data.sort_values("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ", ascending=False)

        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –ø—Ä–æ—Ü–µ–Ω—Ç –æ—Ç –æ–±—â–µ–≥–æ
        total_to_dest = dest_data["–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ"].sum()
        dest_data["–ü—Ä–æ—Ü–µ–Ω—Ç"] = (dest_data["–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ"] / total_to_dest * 100).round(2)

        destinations_detail[dest_city] = {
            "total_received": total_to_dest,
            "sources": dest_data,
            "unique_sources": len(dest_data),
        }

    return {
        "df": df_clean,
        "from_col": from_col,
        "to_col": to_col,
        "analysis_name": analysis_name,
        "destinations_total": destinations_total,
        "destinations_detail": destinations_detail,
        "pivot_table": pivot_table,
        "total_records": total_records,
    }


# ===== –§–£–ù–ö–¶–ò–ò –î–õ–Ø –°–û–ó–î–ê–ù–ò–Ø EXCEL –û–¢–ß–ï–¢–ê –° –ü–†–ê–í–ò–õ–¨–ù–´–ú–ò –ù–ê–ó–í–ê–ù–ò–Ø–ú–ò =====
def create_excel_report_with_proper_names(df, all_analyses, all_destination_analyses):
    """–°–æ–∑–¥–∞–µ—Ç Excel –æ—Ç—á–µ—Ç —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏ –Ω–∞–∑–≤–∞–Ω–∏—è–º–∏ –∏–∑ –ø–µ—Ä–≤–æ–≥–æ –∫–æ–¥–∞"""
    from io import BytesIO

    # –°–æ–∑–¥–∞–µ–º —Ä–∞–±–æ—á—É—é –∫–Ω–∏–≥—É
    wb = Workbook()

    # –£–¥–∞–ª—è–µ–º –ª–∏—Å—Ç –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
    if "Sheet" in wb.sheetnames:
        ws_default = wb["Sheet"]
        wb.remove(ws_default)

    # 1. –õ–∏—Å—Ç —Å –∏—Å—Ö–æ–¥–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
    ws_source = wb.create_sheet("–ò—Å—Ö–æ–¥–Ω—ã–µ_–¥–∞–Ω–Ω—ã–µ")
    add_source_data_sheet(ws_source, df, all_analyses)

    # 2. –õ–∏—Å—Ç—ã –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
    for analysis_type, analysis_data in all_analyses.items():
        analysis_name = analysis_data["analysis_name"]

        # –õ–∏—Å—Ç —Å —Ç—Ä–∞—Ñ–∏–∫–æ–º –º–µ–∂–¥—É —Ç–æ—á–∫–∞–º–∏
        ws_traffic = wb.create_sheet(f"–¢—Ä–∞—Ñ–∏–∫_{analysis_name}")
        add_traffic_sheet(ws_traffic, analysis_data)

        # –õ–∏—Å—Ç —Å –º–∞—Ç—Ä–∏—Ü–µ–π —Ç—Ä–∞—Ñ–∏–∫–∞ (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –Ω–µ —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–∞—è)
        if (
            not analysis_data["traffic_matrix"].empty
            and analysis_data["traffic_matrix"].shape[0] <= 30
            and analysis_data["traffic_matrix"].shape[1] <= 30
        ):
            ws_matrix = wb.create_sheet(f"–ú–∞—Ç—Ä–∏—Ü–∞_{analysis_name}")
            add_traffic_matrix_sheet(ws_matrix, analysis_data)

    # 3. –õ–∏—Å—Ç—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ø–æ –≥–æ—Ä–æ–¥–∞–º –ø—Ä–∏–±—ã—Ç–∏—è (–µ—Å–ª–∏ –µ—Å—Ç—å)
    if all_destination_analyses:
        for analysis_type, dest_analysis in all_destination_analyses.items():
            analysis_name = dest_analysis["analysis_name"]

            # –õ–∏—Å—Ç —Å –æ–±—â–∏–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –ø–æ –≥–æ—Ä–æ–¥–∞–º –ø—Ä–∏–±—ã—Ç–∏—è
            ws_dest_summary = wb.create_sheet(f"–ú–µ—Å—Ç–æ_–ø—Ä–∏–±—ã—Ç–∏—è_{analysis_name}")
            add_destinations_summary_sheet(ws_dest_summary, dest_analysis)

            # –õ–∏—Å—Ç —Å –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏–µ–π –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
            ws_dest_detail = wb.create_sheet(f"–î–µ—Ç–∞–ª–∏–∑–∞—Ü–∏—è_–∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤_{analysis_name}")
            add_detailed_sources_sheet(ws_dest_detail, dest_analysis)

    # 4. –õ–∏—Å—Ç —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ–± –∞–Ω–∞–ª–∏–∑–µ
    ws_info = wb.create_sheet("–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è")
    add_info_sheet(ws_info, all_analyses)

    # 5. –õ–∏—Å—Ç —Å–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π
    ws_stats = wb.create_sheet("–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞")
    add_statistics_sheet(ws_stats, all_analyses, all_destination_analyses)

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –±—É—Ñ–µ—Ä
    buffer = BytesIO()
    wb.save(buffer)
    buffer.seek(0)
    return buffer


def add_source_data_sheet(ws, df, all_analyses):
    """–î–æ–±–∞–≤–ª—è–µ—Ç –ª–∏—Å—Ç —Å –∏—Å—Ö–æ–¥–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏"""
    # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
    columns_to_save = []
    for analysis_type, analysis_data in all_analyses.items():
        from_col = analysis_data["from_col"]
        to_col = analysis_data["to_col"]
        if from_col not in columns_to_save:
            columns_to_save.append(from_col)
        if to_col not in columns_to_save:
            columns_to_save.append(to_col)

    # –î–æ–±–∞–≤–ª—è–µ–º –µ—â–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ –≤–∞–∂–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫ –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å
    additional_cols = [
        "–ê—Ä—Ç–∏–∫—É–ª –ø—Ä–æ–¥–∞–≤—Ü–∞",
        "–ù–∞–∑–≤–∞–Ω–∏–µ",
        "–ë—Ä–µ–Ω–¥",
        "–°—Ç–æ–∏–º–æ—Å—Ç—å",
        "–î–∞—Ç–∞ –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏—è –∑–∞–∫–∞–∑–∞",
    ]
    for col in additional_cols:
        if col in df.columns and col not in columns_to_save:
            columns_to_save.append(col)

    # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏
    ws.append(columns_to_save)

    # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ (–ø–µ—Ä–≤—ã–µ 1000 —Å—Ç—Ä–æ–∫ –¥–ª—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏)
    max_rows = min(1000, len(df))
    for idx, row in df.head(max_rows).iterrows():
        row_data = [row[col] if col in df.columns else "" for col in columns_to_save]
        ws.append(row_data)

    # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
    for i, col in enumerate(columns_to_save, 1):
        col_letter = get_column_letter(i)
        ws.column_dimensions[col_letter].width = 25

        for cell in ws[col_letter]:
            if cell.row == 1:
                cell.font = Font(bold=True, size=11)
                cell.fill = PatternFill(
                    start_color="E0E0E0", end_color="E0E0E0", fill_type="solid"
                )
            cell.alignment = Alignment(wrap_text=True, vertical="center")


def add_traffic_sheet(ws, analysis_data):
    """–î–æ–±–∞–≤–ª—è–µ—Ç –ª–∏—Å—Ç —Å —Ç—Ä–∞—Ñ–∏–∫–æ–º –º–µ–∂–¥—É —Ç–æ—á–∫–∞–º–∏"""
    analysis_name = analysis_data["analysis_name"]

    ws.append(
        [
            f"{analysis_name} –æ—Ç–ø—Ä–∞–≤–∫–∏",
            f"{analysis_name} –ø—Ä–∏–±—ã—Ç–∏—è",
            "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–µ—Ä–µ–≤–æ–∑–æ–∫",
        ]
    )

    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫ –¥–ª—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    max_traffic_rows = min(500, len(analysis_data["traffic_volume"]))
    for _, row in analysis_data["traffic_volume"].head(max_traffic_rows).iterrows():
        ws.append(
            [
                row[analysis_data["from_col"]],
                row[analysis_data["to_col"]],
                row["–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ"],
            ]
        )

    # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
    for col in ["A", "B", "C"]:
        ws.column_dimensions[col].width = 35
        for cell in ws[col]:
            if cell.row == 1:
                cell.font = Font(bold=True, size=11)
                cell.fill = PatternFill(
                    start_color="E0E0E0", end_color="E0E0E0", fill_type="solid"
                )
            cell.alignment = Alignment(wrap_text=True, vertical="center")


def add_traffic_matrix_sheet(ws, analysis_data):
    """–î–æ–±–∞–≤–ª—è–µ—Ç –ª–∏—Å—Ç —Å –º–∞—Ç—Ä–∏—Ü–µ–π —Ç—Ä–∞—Ñ–∏–∫–∞"""
    matrix = analysis_data["traffic_matrix"]
    if matrix.empty:
        ws["A1"] = "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –º–∞—Ç—Ä–∏—Ü—ã"
        return

    # –ó–∞–≥–æ–ª–æ–≤–∫–∏
    headers = [f'{analysis_data["analysis_name"]} –æ—Ç–ø—Ä–∞–≤–∫–∏ ‚Üí'] + list(matrix.columns)
    ws.append(headers)

    # –î–∞–Ω–Ω—ã–µ
    for location in matrix.index:
        row_data = [location] + list(matrix.loc[location].values)
        ws.append(row_data)

    # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
    ws.column_dimensions["A"].width = 35
    for i in range(2, len(matrix.columns) + 2):
        col_letter = get_column_letter(i)
        ws.column_dimensions[col_letter].width = 12

    for row in ws.iter_rows(
        min_row=1, max_row=len(matrix) + 1, min_col=1, max_col=len(matrix.columns) + 1
    ):
        for cell in row:
            if cell.row == 1 or cell.column == 1:
                cell.font = Font(bold=True)
                cell.fill = PatternFill(
                    start_color="F0F0F0", end_color="F0F0F0", fill_type="solid"
                )
                cell.alignment = Alignment(horizontal="center", vertical="center")
            else:
                cell.alignment = Alignment(horizontal="center", vertical="center")
                cell.border = Border(
                    left=Side(style="thin"),
                    right=Side(style="thin"),
                    top=Side(style="thin"),
                    bottom=Side(style="thin"),
                )


def add_destinations_summary_sheet(ws, dest_analysis):
    """–î–æ–±–∞–≤–ª—è–µ—Ç –ª–∏—Å—Ç —Å –æ–±—â–∏–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –ø–æ –≥–æ—Ä–æ–¥–∞–º –ø—Ä–∏–±—ã—Ç–∏—è"""
    analysis_name = dest_analysis["analysis_name"]

    ws.append([f"{analysis_name} –ø—Ä–∏–±—ã—Ç–∏—è", "–í—Å–µ–≥–æ –ø–æ—Å—Ç—É–ø–ª–µ–Ω–∏–π", "–ü—Ä–æ—Ü–µ–Ω—Ç –æ—Ç –æ–±—â–µ–≥–æ"])

    for _, row in dest_analysis["destinations_total"].iterrows():
        city = row[dest_analysis["to_col"]]
        total = row["–í—Å–µ–≥–æ_–ø–æ—Å—Ç—É–ø–ª–µ–Ω–∏–π"]
        percentage = total / dest_analysis["total_records"] * 100
        ws.append([city, total, f"{percentage:.2f}%"])

    # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
    ws.column_dimensions["A"].width = 35
    ws.column_dimensions["B"].width = 20
    ws.column_dimensions["C"].width = 20

    for row in ws.iter_rows(min_row=1, max_row=ws.max_row):
        for cell in row:
            if cell.row == 1:
                cell.font = Font(bold=True, size=11)
                cell.fill = PatternFill(
                    start_color="E0E0E0", end_color="E0E0E0", fill_type="solid"
                )
            cell.alignment = Alignment(horizontal="center", vertical="center")
            cell.border = Border(
                left=Side(style="thin"),
                right=Side(style="thin"),
                top=Side(style="thin"),
                bottom=Side(style="thin"),
            )


def add_detailed_sources_sheet(ws, dest_analysis):
    """–î–æ–±–∞–≤–ª—è–µ—Ç –ª–∏—Å—Ç —Å –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏–µ–π –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –¥–ª—è –≥–æ—Ä–æ–¥–æ–≤ –ø—Ä–∏–±—ã—Ç–∏—è"""
    analysis_name = dest_analysis["analysis_name"]

    current_row = 1

    # –ü—Ä–æ—Ö–æ–¥–∏–º –ø–æ —Ç–æ–ø-30 –≥–æ—Ä–æ–¥–∞–º –ø—Ä–∏–±—ã—Ç–∏—è
    top_destinations = dest_analysis["destinations_total"].head(30)

    for dest_idx, (_, dest_row) in enumerate(top_destinations.iterrows(), 1):
        dest_city = dest_row[dest_analysis["to_col"]]
        total_received = dest_row["–í—Å–µ–≥–æ_–ø–æ—Å—Ç—É–ø–ª–µ–Ω–∏–π"]

        # –ó–∞–≥–æ–ª–æ–≤–æ–∫ –¥–ª—è –≥–æ—Ä–æ–¥–∞ –ø—Ä–∏–±—ã—Ç–∏—è
        ws.merge_cells(
            start_row=current_row, start_column=1, end_row=current_row, end_column=4
        )
        title_cell = ws.cell(row=current_row, column=1)
        title_cell.value = (
            f"{dest_idx}. {dest_city} - –í—Å–µ–≥–æ –ø–æ—Å—Ç—É–ø–ª–µ–Ω–∏–π: {total_received:,}"
        )
        title_cell.font = Font(bold=True, size=12, color="1F4E79")
        title_cell.fill = PatternFill(
            start_color="DDEBF7", end_color="DDEBF7", fill_type="solid"
        )
        title_cell.alignment = Alignment(horizontal="center", vertical="center")

        current_row += 1

        # –ó–∞–≥–æ–ª–æ–≤–∫–∏ —Ç–∞–±–ª–∏—Ü—ã
        headers = ["‚Ññ", f"{analysis_name} –æ—Ç–ø—Ä–∞–≤–∫–∏", "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ", "–ü—Ä–æ—Ü–µ–Ω—Ç"]
        ws.append(headers)

        # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤
        for col in range(1, 5):
            cell = ws.cell(row=current_row, column=col)
            cell.font = Font(bold=True)
            cell.fill = PatternFill(
                start_color="F2F2F2", end_color="F2F2F2", fill_type="solid"
            )
            cell.alignment = Alignment(horizontal="center", vertical="center")
            cell.border = Border(
                left=Side(style="thin"),
                right=Side(style="thin"),
                top=Side(style="thin"),
                bottom=Side(style="thin"),
            )

        current_row += 1

        # –î–∞–Ω–Ω—ã–µ –ø–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º
        if dest_city in dest_analysis["destinations_detail"]:
            sources_data = dest_analysis["destinations_detail"][dest_city]["sources"]

            for src_idx, (_, src_row) in enumerate(
                sources_data.head(20).iterrows(), 1
            ):  # –¢–æ–ø-20 –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
                source_city = src_row[dest_analysis["from_col"]]
                count = src_row["–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ"]
                percent = src_row["–ü—Ä–æ—Ü–µ–Ω—Ç"]

                ws.append([src_idx, source_city, count, f"{percent}%"])

                # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—Ç—Ä–æ–∫–∏
                for col in range(1, 5):
                    cell = ws.cell(row=current_row, column=col)
                    cell.alignment = Alignment(horizontal="center", vertical="center")
                    cell.border = Border(
                        left=Side(style="thin"),
                        right=Side(style="thin"),
                        top=Side(style="thin"),
                        bottom=Side(style="thin"),
                    )

                    # –ü–æ–¥—Å–≤–µ—Ç–∫–∞ —á–µ—Ç–Ω—ã—Ö —Å—Ç—Ä–æ–∫
                    if current_row % 2 == 0:
                        cell.fill = PatternFill(
                            start_color="F8F8F8", end_color="F8F8F8", fill_type="solid"
                        )

                current_row += 1
        else:
            ws.append(["", "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö", "", ""])
            current_row += 1

        # –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É –º–µ–∂–¥—É –≥–æ—Ä–æ–¥–∞–º–∏
        current_row += 2

    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —à–∏—Ä–∏–Ω—ã –∫–æ–ª–æ–Ω–æ–∫
    ws.column_dimensions["A"].width = 5
    ws.column_dimensions["B"].width = 35
    ws.column_dimensions["C"].width = 15
    ws.column_dimensions["D"].width = 12


def add_info_sheet(ws, all_analyses):
    """–î–æ–±–∞–≤–ª—è–µ—Ç –ª–∏—Å—Ç —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ–± –∞–Ω–∞–ª–∏–∑–µ"""
    ws.merge_cells("A1:D1")
    title_cell = ws["A1"]
    title_cell.value = "–ò–ù–§–û–†–ú–ê–¶–ò–Ø –û–ë –ê–ù–ê–õ–ò–ó–ï"
    title_cell.font = Font(bold=True, size=16, color="1F4E79")
    title_cell.alignment = Alignment(horizontal="center", vertical="center")
    title_cell.fill = PatternFill(
        start_color="E2EFDA", end_color="E2EFDA", fill_type="solid"
    )

    # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
    info_data = [
        ["–î–∞—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞", datetime.now().strftime("%Y-%m-%d %H:%M:%S")],
    ]

    for info_item in info_data:
        ws.append(info_item)

    # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–∞–∂–¥–æ–º –∞–Ω–∞–ª–∏–∑–µ
    ws.append(["", ""])
    ws.append(["–í–´–ü–û–õ–ù–ï–ù–ù–´–ï –ê–ù–ê–õ–ò–ó–´:", ""])
    for analysis_type, analysis_data in all_analyses.items():
        ws.append(
            [
                analysis_data["analysis_name"],
                f"{analysis_data['from_col']} ‚Üí {analysis_data['to_col']}",
            ]
        )

    # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–º –∞–Ω–∞–ª–∏–∑–µ
    ws.append(["", ""])
    ws.append(["–ü–†–ò–ú–ï–ß–ê–ù–ò–Ø:", ""])
    notes = [
        "1. –ê–Ω–∞–ª–∏–∑ –≤—ã–ø–æ–ª–Ω–µ–Ω –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º –∫–æ–ª–æ–Ω–æ–∫",
        "2. –î–∞–Ω–Ω—ã–µ –æ—á–∏—â–µ–Ω—ã –æ—Ç –ø—É—Å—Ç—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π",
        "3. –¢–æ–ø –º–∞—Ä—à—Ä—É—Ç—ã –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –ø–µ—Ä–µ–≤–æ–∑–æ–∫",
        "4. –ü–æ–ª–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–æ—Å—Ç—É–ø–Ω—ã –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏—Ö –ª–∏—Å—Ç–∞—Ö",
        "5. –î–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ø–æ –≥–æ—Ä–æ–¥–∞–º —Å–æ–∑–¥–∞–Ω–∞ –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ª–∏—Å—Ç–µ",
    ]

    for note in notes:
        ws.append([note, ""])

    # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
    ws.column_dimensions["A"].width = 50
    ws.column_dimensions["B"].width = 40

    for row in ws.iter_rows(min_row=2):
        for cell in row:
            if cell.row == 2:  # –ó–∞–≥–æ–ª–æ–≤–∫–∏
                cell.font = Font(bold=True)
                cell.fill = PatternFill(
                    start_color="FCE4D6", end_color="FCE4D6", fill_type="solid"
                )

            if cell.row % 2 == 0 and cell.row > 2:
                cell.fill = PatternFill(
                    start_color="F2F2F2", end_color="F2F2F2", fill_type="solid"
                )

            cell.alignment = Alignment(vertical="center", wrap_text=True)


def add_statistics_sheet(ws, all_analyses, all_destination_analyses):
    """–î–æ–±–∞–≤–ª—è–µ—Ç –ª–∏—Å—Ç —Å–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π."""
    ws.merge_cells("A1:C1")
    title_cell = ws["A1"]
    title_cell.value = "–û–ë–©–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ê–ù–ê–õ–ò–ó–ê"
    title_cell.font = Font(bold=True, size=16, color="1F4E79")
    title_cell.alignment = Alignment(horizontal="center", vertical="center")
    title_cell.fill = PatternFill(
        start_color="E2EFDA", end_color="E2EFDA", fill_type="solid"
    )

    row = 3
    for analysis_type, analysis_data in all_analyses.items():
        analysis_name = analysis_data["analysis_name"]

        # –ó–∞–≥–æ–ª–æ–≤–æ–∫ —Ä–∞–∑–¥–µ–ª–∞
        ws.merge_cells(f"A{row}:C{row}")
        section_cell = ws[f"A{row}"]
        section_cell.value = f"–ê–ù–ê–õ–ò–ó {analysis_name.upper()}"
        section_cell.font = Font(bold=True, size=14, color="2E75B6")
        section_cell.fill = PatternFill(
            start_color="FCE4D6", end_color="FCE4D6", fill_type="solid"
        )
        section_cell.alignment = Alignment(horizontal="center")
        row += 1

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        stats_items = [
            ["–ö–æ–ª–æ–Ω–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏", analysis_data["from_col"]],
            ["–ö–æ–ª–æ–Ω–∫–∞ –ø—Ä–∏–±—ã—Ç–∏—è", analysis_data["to_col"]],
            ["–í—Å–µ–≥–æ –ø–µ—Ä–µ–≤–æ–∑–æ–∫", f"{analysis_data['total_records']:,}"],
            ["–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ç–æ—á–µ–∫ –æ—Ç–ø—Ä–∞–≤–∫–∏", analysis_data["unique_sources"]],
            ["–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ç–æ—á–µ–∫ –ø—Ä–∏–±—ã—Ç–∏—è", analysis_data["unique_destinations"]],
            ["–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –º–∞—Ä—à—Ä—É—Ç–æ–≤", analysis_data["unique_routes"]],
            [
                "–í–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ –ø–µ—Ä–µ–≤–æ–∑–∫–∏",
                f"{analysis_data['internal']:,} ({analysis_data['internal_pct']:.1f}%)",
            ],
            [
                "–í–Ω–µ—à–Ω–∏–µ –ø–µ—Ä–µ–≤–æ–∑–∫–∏",
                f"{analysis_data['external']:,} ({analysis_data['external_pct']:.1f}%)",
            ],
        ]
        for stat_name, stat_value in stats_items:
            ws.append([stat_name, stat_value])
            row += 1

        # –¢–æ–ø –º–∞—Ä—à—Ä—É—Ç—ã
        if not analysis_data["top_routes"].empty:
            ws.append(["", ""])
            ws.append([f"–¢–û–ü-10 –ú–ê–†–®–†–£–¢–û–í ({analysis_name.lower()}):", ""])
            row += 2
            for i in range(min(10, len(analysis_data["top_routes"]))):
                route = analysis_data["top_routes"].iloc[i]
                from_val = route[analysis_data["from_col"]]
                to_val = route[analysis_data["to_col"]]
                count = route["–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ"]
                if len(from_val) > 25:
                    from_val = from_val[:22] + "..."
                if len(to_val) > 25:
                    to_val = to_val[:22] + "..."
                ws.append([f"{i+1}. {from_val} ‚Üí {to_val}", f"{count:,}"])
                row += 1

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –≥–æ—Ä–æ–¥–∞–º/—Ä–µ–≥–∏–æ–Ω–∞–º –ø—Ä–∏–±—ã—Ç–∏—è (–µ—Å–ª–∏ –µ—Å—Ç—å)
        if analysis_type in all_destination_analyses:
            dest_analysis = all_destination_analyses[analysis_type]

            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω—É—é —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫—É –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞ –∞–Ω–∞–ª–∏–∑–∞
            if analysis_name == "–ì–æ—Ä–æ–¥–∞":
                destination_type = "–≥–æ—Ä–æ–¥–∞–º"
                destination_single = "–≥–æ—Ä–æ–¥"
            elif analysis_name == "–†–µ–≥–∏–æ–Ω—ã":
                destination_type = "—Ä–µ–≥–∏–æ–Ω–æ–≤"
                destination_single = "—Ä–µ–≥–∏–æ–Ω"
            else:
                destination_type = "—Ç–æ—á–µ–∫ –ø—Ä–∏–±—ã—Ç–∏—è"
                destination_single = "—Ç–æ—á–∫–∞ –ø—Ä–∏–±—ã—Ç–∏—è"

            ws.append(["", ""])
            ws.append([f"–°–¢–ê–¢–ò–°–¢–ò–ö–ê –ü–û {destination_type.upper()} –ü–†–ò–ë–´–¢–ò–Ø:", ""])
            row += 2
            ws.append(
                [
                    f"–í—Å–µ–≥–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö {destination_type} –ø—Ä–∏–±—ã—Ç–∏—è",
                    f"{dest_analysis['destinations_total'].shape[0]}",
                ]
            )
            row += 1
            ws.append([f"–¢–û–ü-10 –ü–û {destination_type.upper()} –ü–û–°–¢–£–ü–õ–ï–ù–ò–Ø–ú:", ""])
            row += 1
            for i in range(min(10, len(dest_analysis["destinations_total"]))):
                dest_row = dest_analysis["destinations_total"].iloc[i]
                destination = dest_row[dest_analysis["to_col"]]
                total = dest_row["–í—Å–µ–≥–æ_–ø–æ—Å—Ç—É–ø–ª–µ–Ω–∏–π"]
                percentage = total / dest_analysis["total_records"] * 100
                if len(destination) > 30:
                    destination = destination[:27] + "..."
                ws.append([f"{i+1}. {destination}", f"{total:,} ({percentage:.1f}%)"])
                row += 1

        row += 2  # –û—Ç—Å—Ç—É–ø –º–µ–∂–¥—É —Ä–∞–∑–¥–µ–ª–∞–º–∏

    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —à–∏—Ä–∏–Ω—ã –∫–æ–ª–æ–Ω–æ–∫
    ws.column_dimensions["A"].width = 50
    ws.column_dimensions["B"].width = 40

    # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
    for row_cells in ws.iter_rows():
        for cell in row_cells:
            if cell.row == 1:
                continue
            if cell.value and isinstance(cell.value, str) and ":" in cell.value:
                cell.font = Font(bold=True)
                cell.alignment = Alignment(vertical="center")
            if cell.row > 2:
                cell.border = Border(
                    left=Side(style="thin"),
                    right=Side(style="thin"),
                    top=Side(style="thin"),
                    bottom=Side(style="thin"),
                )
